{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS OF REAL DATA (GSFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From real MnKa1, MnKa2 (+other lines) data, it creates a library of optimal filters and reconstruct (and calibrate) data calculating FWHM of lines\n",
    "\n",
    "**Energy units are (k)eV**\n",
    "\n",
    "Imports and definitions\n",
    "\n",
    "PROCESSING\n",
    "\n",
    "0. Reconstruct data file (singles) with selected record length and library Ka1 and select HR events\n",
    "\n",
    "1. Read reconstructed events\n",
    "\n",
    "    1.1. Have a look to events distribution and to variations with baseline and jitter\n",
    "   \n",
    "   STUDY OF MnK COMPLEX\n",
    "\n",
    "2. Jitter correction\n",
    "\n",
    "    2.1 Plot recon PH vs PHASE (distance between trigger and parabola fit=PHI+LAGS) & Fit a polynomial\n",
    "    \n",
    "3. Baseline drift correction\n",
    "\n",
    "    3.1 Plot jiterr_recon PH vs Baseline & Fit polynomial\n",
    "    \n",
    "    3.2 Fit gaussians, create new Gain scale and re-calibrate energies\n",
    "    \n",
    "4. Fit histogram of baseline-jitter-corrected energies\n",
    "\n",
    "    4.1. Test different number of bins and see how residuals respond\n",
    "    \n",
    "    4.2. Use the range of number of bins where residuals are quite estable and use them to get different FWHM; then take median value\n",
    "    \n",
    "5. Recalibrate energies\n",
    "\n",
    "6. Plot ALL calibrated energies (No correction for non Mn energies)\n",
    "    - get new gain scale with fitted line centres\n",
    "    - recalibrate energies\n",
    "    - fit again to get FWHM more precisely\n",
    "    \n",
    "7. Plot FWHM comparison of different reconstruction methods/lengths    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "#%matplotlib widget\n",
    "\n",
    "from subprocess import check_call, STDOUT\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import numpy.polynomial.polynomial as poly\n",
    "from numpy.polynomial import Polynomial as P\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "import shutil, shlex\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import pandas\n",
    "import heasoftpy as hsp\n",
    "from RxLines import RxLines\n",
    "from fit2GaussAndRatio import fit2GaussAndRatio\n",
    "from getMaximaDensity import getMaximaDensity\n",
    "from fit2gauss2hist import fit2gauss2hist\n",
    "from fit3gauss2hist import fit3gauss2hist\n",
    "from gainScaleFit import gainScaleLinearFit, gainScalePolyFit\n",
    "from fitVoigt2hist import fitVoigt2hist\n",
    "from applyCorr import applyCorr\n",
    "from commands import run_comm\n",
    "from clean_records import remove_invalid_records\n",
    "from annote import AnnoteFinder\n",
    "from GSFC import averagePulse, autoDeterminePulseWindowAndThreshold, categorize, deviatonFromAveragePulse,nrecs_larger_than,chi2\n",
    "\n",
    "\n",
    "import matplotlib.transforms as transforms\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from numpy import random\n",
    "from calibLines import *\n",
    "\n",
    "cwd = os.getcwd()\n",
    "tmpDir = tempfile.mkdtemp()\n",
    "os.environ[\"PFILES\"] = tmpDir + \":\" + os.environ[\"PFILES\"]\n",
    "os.environ[\"HEADASNOQUERY\"] = \"\"\n",
    "os.environ[\"HEADASPROMPT\"] = \"/dev/null/\"\n",
    "xmlfileSX = os.environ[\"SIXTE\"] + \"/share/xifusim/instruments/8pix_tdm.xml\"\n",
    "print(xmlfileSX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data files\n",
    "# 32 channels/column * 8 columns\n",
    "ncols = 8\n",
    "nrows = 32\n",
    "channels_matrix = np.zeros((32,8),dtype=\"i\")\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        iinit=j*nrows*2 + 1\n",
    "        ifin=iinit + nrows*2 \n",
    "        channels_matrix[:,j]=list(range(iinit, ifin, 2))\n",
    "#print(channels_matrix)\n",
    "        \n",
    "channel = 5\n",
    "resDir = \"channel_\" + str(channel)\n",
    "if not os.path.exists(resDir):\n",
    "    os.makedirs(resDir)\n",
    "fileph_singles = resDir + \"/pulse_chan\" + str(channel) + \"_singles.fits\" # initial data file with all records and PH_ID column populated\n",
    "fileph_Kas = resDir + \"/pulse_chan\" + str(channel) + \"_Kas.fits\" # data file with only those records with Kas lines (selected by max(ADC))\n",
    "\n",
    "channel_col = int(channel/(nrows*2))\n",
    "print(\"Matrix column for channel\", channel, \"is\", channel_col)   \n",
    "\n",
    "#noXTfile = resDir + \"/dataKas_noXT.csv\"\n",
    "noXTfile = resDir + \"/Kas_noXT_PHID.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select SIRENA parameters for library Kas creation and reconstruction of data files\n",
    "samprate=195312.5\n",
    "plen = 8000\n",
    "#plen=4096\n",
    "oflen = 8000\n",
    "preBuffer = 2000\n",
    "pBstr = \"\"\n",
    "if preBuffer > 0:\n",
    "    pBstr = \"_pB\" + str(preBuffer)\n",
    "method = \"OPTFILT\"\n",
    "F0orB0 = \"F0\"\n",
    "nS = 5\n",
    "sU = 3\n",
    "sD = 4\n",
    "\n",
    "suffix = pBstr + \"_filt_thS3.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed files\n",
    "evt_libKas = resDir + \"/\" + \"evt_pulse_chan\" + str(channel) + \"_libKas_\" + \"pL\" + str(plen) + \"_\" + method + str(oflen) + suffix + \".fits\"\n",
    "evt_libKas_HR = resDir + \"/\" + \"evt_pulse_chan\" + str(channel) + \"_libKas_\" + \"pL\" + str(plen) + \"_\" + method + str(oflen) + suffix + \"_HR.fits\"\n",
    "evtKas_libKas = resDir + \"/\" + \"evtKas_pulse_chan\" + str(channel) + \"_libKas_\" + \"pL\" + str(plen) + \"_\" + method + str(oflen) + suffix + \".fits\"\n",
    "evtKas_libKas_HR = resDir + \"/\" + \"evtKas_pulse_chan\" + str(channel) + \"_libKas_\" + \"pL\" + str(plen) + \"_\" + method + str(oflen) + suffix + \"_HR.fits\"\n",
    "\n",
    "# library Kas\n",
    "libKas = resDir + \"/\" + \"library_Kas_\"+ str(oflen) + suffix + \".fits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain scale\n",
    "#lines = (MnKa2_cmass, MnKa1_cmass, MnKb_cmass)\n",
    "lines = (MnKa2_cmass, MnKa1_cmass, MnKb.energies_eV[MnKb.ilabels.index(\"Kb1\")])\n",
    "print(\"MnKa2_cmass, MnKa1_cmass, MnKb1\")\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plotMainXlines(ax, alp_l=0.3, alp_t=0.5):\n",
    "    \"\"\" Plot main X line\n",
    "    ax: axis of plot\n",
    "    alp_l: transparency (alpha) of calibration lines markers\n",
    "    alp_t: transparency (alpha) of calibration lines text\n",
    "    \"\"\"\n",
    "    trans=ax.get_xaxis_transform()\n",
    "    colors = 3*[\"green\"] + 3*[\"red\"] + 3*[\"magenta\"] + 3*[\"blue\"] + 3*[\"darkorange\"]\n",
    "    lxx = [\"Ka11\",\"Ka21\",\"Kb11\"]\n",
    "    lx = [\"Ka1\",\"Ka2\",\"Kb\"]\n",
    "    labels = [\"Cr\"+ll for ll in lxx] + [\"Mn\"+ll for ll in lxx] + [\"Cu\"+ll for ll in lxx] + [\"Fe\"+ll for ll in lx] + [\"Co\"+ll for ll in lx]\n",
    "    xpos   = (5414.874,5405.551,5947.000,  #Cr\n",
    "              5898.882,5887.772,6490.890,  #Mn\n",
    "              8047.837,8027.993,8905.532,  #Cu\n",
    "              6403.840,6390.840,7057.980,  #Fe https://xdb.lbl.gov/Section1/Table_1-2.pdf\n",
    "              6930.320,6915.300,7649.400)  #Co https://xdb.lbl.gov/Section1/Table_1-2.pdf\n",
    "    ypos   = np.linspace(0.95,0.05,num=len(colors))\n",
    "    for i in range(len(colors)):\n",
    "        if xpos[i] < ax.get_xlim()[0] or xpos[i] > ax.get_xlim()[1]:\n",
    "            continue\n",
    "        x=xpos[i]\n",
    "        ax.axvline(x, color=colors[i], ls=\":\", alpha=alp_l)\n",
    "        plt.text(x, ypos[i], labels[i], color=colors[i], transform=trans, alpha=alp_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def format_axes(fig):\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        ax.text(0.5, 0.5, \"ax%d\" % (i+1), va=\"center\", ha=\"center\")\n",
    "        ax.tick_params(labelbottom=False, labelleft=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Reconstruct data file (singles & Kas) with selected record length and select HR events\n",
    "(try different record lengths to get variation of FWHM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "#reconstruct ALL events\n",
    "comm = (\"tesreconstruction Recordfile=\" + fileph_singles + \" TesEventFile=\" + evt_libKas + \" PulseLength=\" + str(plen) +\n",
    "        \" LibraryFile=\" + libKas + \" samplesUp=\" + str(sU) + \" nSgms=\" + str(nS) + \" samplesDown=\" + str(sD) +\n",
    "        \" opmode=1 clobber=yes EnergyMethod=\" + method + \" XMLFile=\" + xmlfileSX + \" LbT=0.01\" + \n",
    "        \" filtEeV=\" + str(MnKas_cmass) + \" OFStrategy=FIXED OFLength=\" + str(oflen) + \" preBuffer=\" + str(preBuffer))\n",
    "mess = \"Reconstructing ALL data w/ library (Kas)\"\n",
    "run_comm(comm,msg=mess)\n",
    "print(\"####################################\")\n",
    "print(\"Reconstruction of ALL pulses finished\")\n",
    "print(\"####################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "#reconstruct Mn Kas events\n",
    "comm = (\"tesreconstruction Recordfile=\" + fileph_Kas + \" TesEventFile=\" + evtKas_libKas + \" PulseLength=\" + str(plen) +\n",
    "        \" LibraryFile=\" + libKas + \" samplesUp=\" + str(sU) + \" nSgms=\" + str(nS) + \" samplesDown=\" + str(sD) +\n",
    "        \" opmode=1 clobber=yes EnergyMethod=\" + method + \" XMLFile=\" + xmlfileSX + \" LbT=0.01\" + \n",
    "        \" filtEeV=\" + str(MnKas_cmass) + \" OFStrategy=FIXED OFLength=\" + str(oflen) + \" preBuffer=\" + str(preBuffer))\n",
    "mess = \"Reconstructing Kas data w/ library (Kas)\"\n",
    "run_comm(comm,msg=mess)\n",
    "print(\"####################################\")\n",
    "print(\"Reconstruction of Kas pulses finished\")\n",
    "print(\"####################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# select only HR events (ALL)\n",
    "expr = \"(GRADE1 >= \" + str(min(plen,oflen)) + \" && GRADE2 > 500)\"\n",
    "result = hsp.fselect(infile=evt_libKas, outfile=evt_libKas_HR, expr=expr, clobber=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# select only HR events (Mn Kas)\n",
    "expr = \"(GRADE1 >= \" + str(min(plen,oflen)) + \" && GRADE2 > 500)\"\n",
    "result = hsp.fselect(infile=evtKas_libKas, outfile=evtKas_libKas_HR, expr=expr, clobber=\"yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read reconstructed (ALL) events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulseFile = resDir + \"/pulse.txt\"\n",
    "colname = \"SIGNAL, PH_ID, GRADE1, GRADE2, PHI, LAGS, BSLN\" \n",
    "infile = evt_libKas_HR + \"+1\"\n",
    "print(\"FDUMPing evt file\", infile)\n",
    "result = hsp.fdump(wrap='yes', infile=infile, columns=colname, rows='-', prhead='no', showcol='yes', showunit='no',\n",
    "                   showrow='no', outfile=pulseFile, clobber='yes', pagewidth=256, more='yes')\n",
    "\n",
    "all_singles_data_HR = pandas.read_csv(pulseFile, skiprows=0,sep=\"\\s+\")\n",
    "print(\"\\nNumber of initial (all energies) HR pulses:\", len(all_singles_data_HR)) \n",
    "os.remove(pulseFile)\n",
    "\n",
    "# exclude events with PHI=0. It'll mean that there is a pulse (undetected) over the rise of another one\n",
    "data_HR = all_singles_data_HR[(all_singles_data_HR.PHI>0.) | (all_singles_data_HR.PHI<0)]\n",
    "print(\"\\nNumber of non-excluded events (all energies) HR pulses (after PHI selection):\", len(data_HR)) \n",
    "\n",
    "# exclude high baseline events: they have a truncated pulse at the beginnig of the record\n",
    "data_HR = data_HR[(data_HR.BSLN<8325)]\n",
    "print(\"\\nNumber of non-excluded events (all energies) HR pulses (after BSLN selection):\", len(data_HR)) \n",
    "\n",
    "print(\"MinSIGNAL, MaxSIGNAL=\", min(data_HR.SIGNAL), max(data_HR.SIGNAL))\n",
    "print(\"MinBSLN, MaxBSLN=\", min(data_HR.BSLN), max(data_HR.BSLN))\n",
    "display(data_HR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Have a look to (ALL) events distribution and to variations with baseline and jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main lines in reconstructed PH units\n",
    "PHlines = dict()\n",
    "if plen==8000:\n",
    "    PHlines = {\n",
    "           \"Sc-Ka\": (4.250,4.400),\n",
    "           \"Ti-Ka\": (4.675,4.750),\n",
    "           \"V-Ka\":  (5.050,5.125),\n",
    "           \"Cr-Ka\": (5.400,5.600),\n",
    "           \"Mn-Ka\": (5.860,5.920),\n",
    "           #\"Mn-Ka\": (5.875,5.910),\n",
    "           \"Fe-Ka\": (6.250,6.350),\n",
    "           \"Mn-Kb\": (6.340,6.400),\n",
    "           \"Co-Ka\": (6.630,6.800),\n",
    "           \"Ni-Ka\": (7.050,7.150),\n",
    "           \"Cu-Ka\": (7.450,7.550),\n",
    "           \"Zn-Ka\": (7.900,7.950),\n",
    "           \"Ge-Ka\": (8.700,8.790),\n",
    "           \"Br-Ka\": (9.800,10.100)\n",
    "    } \n",
    "elif plen==4096:\n",
    "    PHlines = {\n",
    "           \"Sc-Ka\": (6.250,6.350),\n",
    "           \"Ti-Ka\": (6.650,6.730),\n",
    "           \"V-Ka\":  (7.000,7.100),\n",
    "           \"Cr-Ka\": (7.400,7.550),\n",
    "           \"Mn-Ka\": (7.830,7.880),\n",
    "           \"Fe-Ka\": (8.200,8.300),\n",
    "           \"Mn-Kb\": (8.310,8.350),\n",
    "           \"Co-Ka\": (8.600,8.730),\n",
    "           \"Ni-Ka\": (9.050,9.100),\n",
    "           \"Cu-Ka\": (9.400,9.550),\n",
    "           \"Zn-Ka\": (9.850,9.950),\n",
    "           \"Ge-Ka\": (10.700,10.790),\n",
    "           \"Br-Ka\": (11.900,12.050)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "# Events PH distribution\n",
    "plt.close()\n",
    "fig = plt.figure(constrained_layout=True, figsize=(10,8))\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "# Have a look to histogram of ALL reconstructed data\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "npulses = len(data_HR.SIGNAL)\n",
    "ax1.set_xlabel(\"Reconstructed PH (ma.u.)\")\n",
    "ax1.set_ylabel(\"#events\")\n",
    "ax1.set_title((\"Distribution of ALL events (\" + str(npulses) + \")\"))\n",
    "ax1.hist(1e3*data_HR.SIGNAL, bins=2000, density=False, label=\"Histogram\", alpha=0.5, log=True)\n",
    "xmin = 1e3*PHlines[\"Sc-Ka\"][0] - 1500\n",
    "xmax = 1e3*PHlines[\"Br-Ka\"][1] + 1500\n",
    "ax1.set_xlim(xmin,xmax)\n",
    "for line in PHlines:\n",
    "    PHmin,PHmax = PHlines[line]\n",
    "    if line == \"Mn-Ka\":\n",
    "        ax1.text(1e3*PHmin, 4e3, line)\n",
    "    else:\n",
    "        ax1.text(1e3*PHmin, 3e3*random.uniform(0.1,0.7), line)\n",
    "\n",
    "# Have a look to histogram of Mn Kas\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "minPH,maxPH = PHlines[\"Mn-Ka\"]\n",
    "npulses = len(data_HR[(data_HR.SIGNAL>minPH) & (data_HR.SIGNAL<maxPH)].SIGNAL)\n",
    "ax2.hist(1e3*data_HR[(data_HR.SIGNAL>minPH) & (data_HR.SIGNAL<maxPH)].SIGNAL, bins=100, density=False, label=\"Histogram\", alpha=0.5, color=\"tab:red\")\n",
    "ax2.set_xlabel(\"Reconstructed PH (a.u.)\")\n",
    "ax2.set_ylabel(\"# events\")\n",
    "ax2.set_title((\"Distribution of Mn Kas events (\" + str(npulses) + \")\"))\n",
    "ax2.set_xlim(1e3*minPH,1e3*maxPH)\n",
    "#ax3.set_xlim(8650,8900) # 0-pad 2048\n",
    "#ax3.set_xlim(9750,9900) # 0-pad 1024\n",
    "\n",
    "# Have a look to histogram of Kb\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "(minPH,maxPH) = PHlines[\"Mn-Kb\"]\n",
    "#(minKb,maxKb) = (9.210, 9.310) # 0-pad 2048\n",
    "#(minKb,maxKb) = (10.275, 10.350) # 0-pad\n",
    "npulses = len(data_HR[(data_HR.SIGNAL>minPH) & (data_HR.SIGNAL<maxPH)].SIGNAL)\n",
    "ax3.hist(1e3*data_HR[(data_HR.SIGNAL>minPH) & (data_HR.SIGNAL<maxPH)].SIGNAL, bins=100, density=False, label=\"Histogram\", alpha=0.5, color=\"tab:red\")\n",
    "ax3.set_xlabel(\"Reconstructed PH (a.u.)\")\n",
    "ax3.set_ylabel(\"# events\")\n",
    "ax3.set_title((\"Distribution of Mn Kb events (\" + str(npulses) + \")\"))\n",
    "ax3.set_xlim(1e3*minPH,1e3*maxPH)\n",
    "#ax4.set_xlim(9210,9310) # 0-pad 2048\n",
    "#ax4.set_xlim(10275,10350) # 0-pad 1024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "i = 0\n",
    "for line in PHlines:\n",
    "    i+=1\n",
    "    color=\"C\"+str(i)\n",
    "    #print(\"Plotting line=\", PHlines[line])\n",
    "    PHmin,PHmax = PHlines[line]\n",
    "    npulses = len(data_HR[(data_HR.SIGNAL>PHmin) & (data_HR.SIGNAL<PHmax)].SIGNAL)\n",
    "    ax = fig.add_subplot(4, 4, i)\n",
    "    dataLine = data_HR[(data_HR.SIGNAL>PHmin) & (data_HR.SIGNAL<PHmax)].SIGNAL\n",
    "    ax.hist(1e3*dataLine, bins=80, density=False, alpha=0.5, color=color, label=line)\n",
    "    ax.set_xlabel(\"Reconstructed PH (a.u.)\")\n",
    "    ax.set_ylabel(\"# events\")\n",
    "    ax.set_xlim(1e3*PHmin,1e3*PHmax)\n",
    "    ax.legend()\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot jitters\n",
    "plt.close()\n",
    "phase_HR = data_HR.PHI + data_HR.LAGS\n",
    "base_HR = data_HR.BSLN\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_xlabel(\"Phase (samples)\")\n",
    "ax1.set_ylabel(\"ReconPH\")\n",
    " \n",
    "for line in PHlines:\n",
    "    PHmin,PHmax = PHlines[line]\n",
    "    dataLine = data_HR[(data_HR.SIGNAL>PHmin) & (data_HR.SIGNAL<PHmax)]\n",
    "    phase_HR = dataLine.PHI + dataLine.LAGS\n",
    "    phase_HR = dataLine.PHI \n",
    "    # arrival phase to (-0.5,0.5) interval\n",
    "    lagPhase = phase_HR - 1.*np.trunc(phase_HR/0.5)\n",
    "    ax1.scatter(lagPhase, dataLine.SIGNAL, alpha=0.5,s=0.05, color=\"red\")\n",
    "    tit = \"Data around calibration lines (pixel \" + str(channel) + \")\"\n",
    "    ax1.set_title(tit)\n",
    "    #ax1.scatter(phase_HR, dataLine.LAGS, alpha=0.5)\n",
    "    \n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_xlabel(\"Phase (samples)\")\n",
    "ax2.set_ylabel(\"ReconPH\")\n",
    "#lagPhase = all_singles_data_HR.PHI - 1.*np.trunc(all_singles_data_HR.PHI/0.5)\n",
    "#ax2.scatter(lagPhase, all_singles_data_HR.SIGNAL, alpha=0.5,s=0.05, color=\"blue\")\n",
    "lagPhase = data_HR.PHI - 1.*np.trunc(data_HR.PHI/0.5)\n",
    "#lagPhase = data_HR.PHI\n",
    "ax2.scatter(lagPhase, data_HR.SIGNAL, alpha=0.5,s=0.05, color=\"red\")\n",
    "#ax2.set_ylim(3.5,10.5)\n",
    "tit = \"All single events data (pixel \" + str(channel) + \")\"\n",
    "ax2.set_title(tit)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,10))\n",
    "i = 0\n",
    "for line in PHlines:\n",
    "    i+=1\n",
    "    #print(\"Plotting line=\", PHlines[line])\n",
    "    PHmin,PHmax = PHlines[line]\n",
    "    dataLine = data_HR[(data_HR.SIGNAL>PHmin) & (data_HR.SIGNAL<PHmax)]\n",
    "    dataLine_norm = dataLine.SIGNAL/(np.median(dataLine.SIGNAL))\n",
    "    phase_HR = dataLine.PHI + dataLine.LAGS\n",
    "    phase_HR = dataLine.PHI - 1.*np.trunc(dataLine.PHI/0.5)\n",
    "    ax1 = fig.add_subplot(4, 4, i)\n",
    "    ax1.set_xlabel(\"Phase (samples)\")\n",
    "    ax1.set_ylabel(\"ReconPH/medianPH\")\n",
    "    title = \"Distribution of \" + line + \" events\"\n",
    "    ax1.set_title(title)\n",
    "    ax1.scatter(phase_HR, dataLine_norm, alpha=0.5,s=0.03)\n",
    "    #ax1.scatter(phase_HR, dataLine.LAGS, alpha=0.5)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jitter and baseline distribution\n",
    "plt.close()\n",
    "phase_HR = data_HR.PHI + data_HR.LAGS\n",
    "base_HR = data_HR.BSLN\n",
    "\n",
    "tit = \"Distribution of ALL events (pixel )\" + str(channel) + \")\"\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax1.set_xlabel(\"Lag (samples)\")\n",
    "ax1.set_ylabel(\"Reconstructed PH (a.u.)\")\n",
    "ax1.set_title(tit)\n",
    "ax1.scatter(phase_HR, data_HR.SIGNAL, alpha=0.5, s=0.03)\n",
    "\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax2.set_xlabel(\"Baseline (ADC a.u.)\")\n",
    "ax2.set_ylabel(\"Reconstructed PH (a.u.)\")\n",
    "ax2.set_title(tit)\n",
    "ax2.scatter(base_HR, data_HR.SIGNAL, alpha=0.2, s=0.03)\n",
    "\n",
    "line = \"Mn-Ka\"\n",
    "PHmin,PHmax = PHlines[line]\n",
    "dataLine = data_HR[(data_HR.SIGNAL>PHmin) & (data_HR.SIGNAL<PHmax)]\n",
    "dataLine_norm = dataLine.SIGNAL/(np.median(dataLine.SIGNAL))\n",
    "phase_HR = dataLine.PHI - 1.*np.trunc(dataLine.PHI/0.5)\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax3.set_xlabel(\"Phase (samples)\")\n",
    "ax3.set_ylabel(\"ReconPH/medianPH\")\n",
    "title = \"Distribution of \" + line + \" events\"\n",
    "ax3.set_title(title)\n",
    "ax3.scatter(phase_HR, dataLine_norm, alpha=0.8,s=0.03)\n",
    "ax3.set_ylim(0.997,1.002)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STUDY Mn K complex "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read reconstructed (Kas) events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulseFile = resDir + \"/pulse.txt\"\n",
    "colname = \"TIME,SIGNAL, PH_ID, GRADE1, GRADE2, PHI, LAGS, BSLN\" \n",
    "infile = evtKas_libKas_HR + \"+1\"\n",
    "print(\"FDUMPing evt file\", infile)\n",
    "result = hsp.fdump(wrap='yes', infile=infile, columns=colname, rows='-', prhead='no', showcol='yes', showunit='no',\n",
    "                   showrow='no', outfile=pulseFile, clobber='yes', pagewidth=256, more='yes')\n",
    "\n",
    "dataKas_HR = pandas.read_csv(pulseFile, skiprows=0,sep=\"\\s+\")\n",
    "#print(\"\\nNumber of initial (all energies) HR pulses:\", len(data_HR)) \n",
    "os.remove(pulseFile)\n",
    "if len(dataKas_HR[dataKas_HR.PHI == 0.].PHI >0):\n",
    "    print(\"Warning: some dataKas have PHI==0. => double undetected pulse?\")\n",
    "\n",
    "display(dataKas_HR)\n",
    "print(\"MinSIGNAL, MaxSIGNAL=\", min(dataKas_HR.SIGNAL), max(dataKas_HR.SIGNAL))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Remove XT from files in same TDM column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# reconstruct pulses in the other files of the same column\n",
    "for ich in channels_matrix[:,channel_col]:\n",
    "    colDir = \"channel_\" + str(ich)\n",
    "    if not os.path.exists(colDir):\n",
    "        os.makedirs(colDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "t1 = 0.002 # (s) dT backwards according to GSFC doc\n",
    "t2 = 0.002 # (s) dT forwards\n",
    "time_window = [t1, t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# reconstruct events in Low res mode, because only ARRIVAL TIME (detection) in interesting\n",
    "print (\"Reconstructing events for colum of channel\", channel)\n",
    "for ich in channels_matrix[:,channel_col]:\n",
    "    if ich==channel:\n",
    "        continue\n",
    "    file_same_col = \"/run/media/ceballos/datar2/pulse_chan\" + str(ich) + \".fits\"\n",
    "    fileXT = \"pulse_detection_chan\" + str(ich) + \".fits\" #Full events file in channel ich\n",
    "    if os.path.isfile(file_same_col) and not os.path.isfile(fileXT) :\n",
    "        comm = (\"tesreconstruction Recordfile=\" + file_same_col + \" TesEventFile=\" + fileXT + \" PulseLength=\" + str(oflen) +\n",
    "            \" LibraryFile=\" + libKas + \" samplesUp=\" + str(sU) + \" nSgms=\" + str(nS) + \" samplesDown=\" + str(sD) +\n",
    "            \" opmode=1 clobber=yes EnergyMethod=\" + method + \" XMLFile=\" + xmlfileSX + \" LbT=0.01\" + \n",
    "            \" filtEeV=\" + str(MnKas_cmass) + \" OFStrategy=FIXED OFLength=8\")\n",
    "        mess = \"detecting pulses for channel:\" + str(ich)\n",
    "        run_comm(comm,msg=mess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "dataKas_noXT = dataKas_HR.copy() # inititalize non-XT events\n",
    "print(\"Starting with non-XT\", len(dataKas_noXT.SIGNAL),\" Kas events in channel\", channel)\n",
    "\n",
    "# Select only non-XT events\n",
    "for ich in channels_matrix[:,channel_col]:\n",
    "    print (\"Analysing events in channel\", ich)\n",
    "    if ich==channel:\n",
    "        continue\n",
    "    fileXT = \"pulse_detection_chan\" + str(ich) + \".fits\" #Full events file in channel ich\n",
    "    if os.path.isfile(fileXT) :\n",
    "        f = fits.open(fileXT)\n",
    "        TIMExt = f[\"EVENTS\"].data['TIME']\n",
    "        PHIDxt = f[\"EVENTS\"].data['PH_ID']\n",
    "        f.close()\n",
    "        # look for events in fileXT synchronous with evts in fileph_Kas    \n",
    "    \n",
    "        xt0 = len(dataKas_noXT.TIME)\n",
    "        for i in range(len(TIMExt)):\n",
    "            #dataKas_noXT = dataKas_noXT[(abs(dataKas_noXT.TIME-TIMExt[i])>sepTH)]\n",
    "            dataKas_noXT = dataKas_noXT[((dataKas_noXT.TIME-TIMExt[i])>t1) | \n",
    "                                       ((TIMExt[i]-dataKas_noXT.TIME)>t2)] \n",
    "            #dataKas_XT = dataKas_HR[(abs(dataKas_HR.TIME-TIMExt[i])<sepTH)]\n",
    "            #if len(dataKas_XT.TIME >0):\n",
    "            #    display(dataKas_HR[(abs(dataKas_HR.TIME-TIMExt[i])<sepTH)])\n",
    "            #time_dist = np.abs(np.array(dataKas_HR.TIME)-TIMExt[i])\n",
    "            #idx_close = np.argwhere(time_dist < sepTH)[:,0]\n",
    "            #if len(idx_close)>0:\n",
    "            #    print(\"XT photon\", i, \"in channel\", ich, \"is very close to Kas photon(s) in df row:\",idx_close)\n",
    "        xt1 = len(dataKas_noXT.TIME)    \n",
    "        if xt1 < xt0:\n",
    "            diff=xt0-xt1\n",
    "            print(\"Removed\",diff,\"photons from channel\",channel,\" which have (channel\",ich,\") XT photons in pulse length\")\n",
    "            print(\"Current number of non-XT events in channel\", channel,\" is \", len(dataKas_noXT.TIME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "rem = len(dataKas_HR.TIME) - len(dataKas_noXT.TIME)\n",
    "print(\"Initial Kas photons:\", len(dataKas_HR.TIME))\n",
    "print(\"Removed\", rem, \"photons from channel\", channel, \"list\")\n",
    "print(\"Remining photons:\", len(dataKas_noXT.TIME))\n",
    "display(dataKas_noXT)\n",
    "Kas_noXT_PHID = dataKas_noXT.PH_ID.to_numpy()\n",
    "display(Kas_noXT_PHID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save or read file with PH_ID of non-XT events (reconstruction method changes pandas datasets (SIGNAL, PHI))\n",
    "if os.path.isfile(noXTfile):\n",
    "    Kas_noXT_PHID = np.loadtxt(noXTfile)\n",
    "else:\n",
    "    np.savetxt(noXTfile, Kas_noXT_PHID)\n",
    "dataKas_noXT = dataKas_HR[(dataKas_HR.PH_ID.isin(Kas_noXT_PHID))]\n",
    "display(dataKas_noXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jitter correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Plot Pulse Height vs PHASE (distance between trigger and parabola fit = PHI) & fit polynomial\n",
    "Phase = PHI\n",
    "Lags = PHI + LAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig = plt.figure(figsize=(9, 7))\n",
    "fig.suptitle(\"Jitter correction\")\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "ax4 = fig.add_subplot(2,2,4)\n",
    "# \n",
    "PHminKas, PHmaxKas = PHlines[\"Mn-Ka\"] \n",
    "PHminKb, PHmaxKb = PHlines[\"Mn-Kb\"]\n",
    "\n",
    "# dataKas_HR already read above; dataKb not corrected for XT!\n",
    "dataKb_HR = data_HR[(data_HR.SIGNAL>PHminKb) & (data_HR.SIGNAL<PHmaxKb)]\n",
    "\n",
    "#print(\"Number of pulses in dataKas_HR: \", len(dataKas_HR))\n",
    "#phaseKas_HR = dataKas_HR.PHI + dataKas_HR.LAGS\n",
    "\n",
    "# apply jitter correction to Kas\n",
    "print(\"Number of pulses in dataKas_noXT: \", len(dataKas_noXT))\n",
    "phaseKas_HR = dataKas_noXT.PHI + dataKas_noXT.LAGS\n",
    "phaseKas_HR = dataKas_noXT.PHI - 1.*np.trunc(dataKas_noXT.PHI/0.5)\n",
    "\n",
    "jitterCorr = applyCorr(xdata=phaseKas_HR,ydata=dataKas_noXT.SIGNAL, deg=4,verbose=0)\n",
    "dataKas_HR_jitter = jitterCorr.ydata_corr\n",
    "jitterCorr.plotDataFit(ax0=ax1, alpha=0.5, size=1)\n",
    "ax1.set_xlabel(\"Phase (samples)\")\n",
    "ax1.set_ylabel(\"PH (a.u.)\")\n",
    "ax1.text(0.90, 0.90, \"Mn-Ka\",verticalalignment='bottom', horizontalalignment='right',\n",
    "        transform=ax1.transAxes, fontsize=12)\n",
    "#        check correction...is flat now?\n",
    "jitterCorr.plotDataCorrFit(ax0=ax2, alpha=0.5, size=1)\n",
    "ax2.set_xlabel(\"Phase (samples)\")\n",
    "ax2.set_ylabel(\"Corrected PH (a.u.)\")\n",
    "ax2.text(0.90, 0.90, \"Mn-Ka\",verticalalignment='bottom', horizontalalignment='right',\n",
    "        transform=ax2.transAxes, fontsize=12)\n",
    "\n",
    "\n",
    "# apply jitter correction to Kb\n",
    "print(\"\\nNumber of pulses in dataKb_HR: \", len(dataKb_HR))\n",
    "phaseKb_HR = dataKb_HR.PHI + dataKb_HR.LAGS\n",
    "phaseKb_HR = dataKb_HR.PHI - 1.*np.trunc(dataKb_HR.PHI/0.5)\n",
    "\n",
    "jitterCorr = applyCorr(xdata=phaseKb_HR,ydata=dataKb_HR.SIGNAL, deg=3,verbose=0)\n",
    "dataKb_HR_jitter = jitterCorr.ydata_corr\n",
    "jitterCorr.plotDataFit(ax0=ax3, alpha=0.5, size=1)\n",
    "ax3.set_xlabel(\"Phase (samples)\")\n",
    "ax3.set_ylabel(\"PH (a.u.)\")\n",
    "ax3.text(0.90, 0.90, \"Mn-Kb\",verticalalignment='bottom', horizontalalignment='right',\n",
    "        transform=ax3.transAxes, fontsize=12)\n",
    "#        check correction...is flat now?\n",
    "jitterCorr.plotDataCorrFit(ax0=ax4, alpha=0.5, size=1)\n",
    "ax4.set_xlabel(\"Phase (samples)\")\n",
    "ax4.set_ylabel(\"Corrected PH (a.u.)\")\n",
    "ax4.text(0.90, 0.90, \"Mn-Kb\",verticalalignment='bottom', horizontalalignment='right',\n",
    "        transform=ax4.transAxes, fontsize=12)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.90])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot jiterr_recon PH vs Baseline & Fit polynomial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig = plt.figure(figsize=(9, 7))\n",
    "fig.suptitle(\"Baseline correction\")\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax2 = fig.add_subplot(2,2,2)\n",
    "\n",
    "#print(\"Mn Kas\")\n",
    "baseKas_HR = dataKas_noXT.BSLN\n",
    "baseCorr = applyCorr(xdata=baseKas_HR,ydata=dataKas_HR_jitter, deg=4,verbose=0)\n",
    "dataKas_HR_jitter_bsln = baseCorr.ydata_corr\n",
    "baseCorr.plotDataFit(ax0=ax1, alpha=0.5, size=1)\n",
    "ax1.set_xlabel(\"Renormalized Baseline (ADC a.u.)\")\n",
    "ax1.set_ylabel(\"PH of events (a.u.)\")\n",
    "ax1.text(0.90, 0.90, \"Mn-Ka\",verticalalignment='bottom', horizontalalignment='right',transform=ax1.transAxes, fontsize=12)\n",
    "baseCorr.plotDataCorrFit(ax0=ax2, alpha=0.5, size=1)\n",
    "ax2.set_xlabel(\"Renormalized Baseline (ADC a.u.)\")\n",
    "ax2.set_ylabel(\"Corrected PH of events (a.u.)\")\n",
    "ax2.text(0.90, 0.90, \"Mn-Ka\",verticalalignment='bottom', horizontalalignment='right',transform=ax2.transAxes, fontsize=12)\n",
    "annotes = dataKas_HR.PH_ID\n",
    "af =  AnnoteFinder(baseKas_HR,dataKas_HR_jitter, annotes, ax=ax1)\n",
    "fig.canvas.mpl_connect('button_press_event', af)\n",
    "\n",
    "#print(\"\\nMn Kb\")\n",
    "ax3 = fig.add_subplot(2,2,3)\n",
    "ax4 = fig.add_subplot(2,2,4)\n",
    "baseKb_HR = dataKb_HR.BSLN\n",
    "baseCorr = applyCorr(xdata=baseKb_HR,ydata=dataKb_HR_jitter, deg=4,verbose=0)\n",
    "dataKb_HR_jitter_bsln = baseCorr.ydata_corr\n",
    "baseCorr.plotDataFit(ax0=ax3, alpha=0.5, size=1)\n",
    "ax3.set_xlabel(\"Renormalized Baseline (ADC a.u.)\")\n",
    "ax3.set_ylabel(\"PH of events (a.u.)\")\n",
    "ax3.text(0.90, 0.90, \"Mn-Kb\",verticalalignment='bottom', horizontalalignment='right',transform=ax3.transAxes, fontsize=12)\n",
    "baseCorr.plotDataCorrFit(ax0=ax4, alpha=0.5, size=1)\n",
    "ax4.set_xlabel(\"Renormalized Baseline (ADC a.u.)\")\n",
    "ax4.set_ylabel(\"Corrected PH of events (a.u.)\")\n",
    "ax4.text(0.90, 0.90, \"Mn-Kb\",verticalalignment='bottom', horizontalalignment='right',transform=ax4.transAxes, fontsize=12)\n",
    "\n",
    "annotes = dataKb_HR.PH_ID\n",
    "af =  AnnoteFinder(baseKb_HR,dataKb_HR_jitter, annotes, ax=ax3)\n",
    "fig.canvas.mpl_connect('button_press_event', af)\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Drift correction (PH versus TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig = plt.figure(figsize=(10, 9))\n",
    "fig.suptitle(\"Drift correction\",fontsize=16)\n",
    "\n",
    "ax1 = fig.add_subplot(4,2,1)\n",
    "ax2 = fig.add_subplot(4,2,2)\n",
    "ax3 = fig.add_subplot(4,2,3)\n",
    "ax4 = fig.add_subplot(4,2,4)\n",
    "ax5 = fig.add_subplot(4,2,5)\n",
    "ax6 = fig.add_subplot(4,2,6)\n",
    "ax7 = fig.add_subplot(4,2,7)\n",
    "ax8 = fig.add_subplot(4,2,8)\n",
    "\n",
    "# FIT DIFFERENT time-intervals\n",
    "\n",
    "time_break1 = 4250 + 1.57869e9\n",
    "time_break2 = 5500 + 1.57869e9\n",
    "#indices1 = np.argwhere(np.array(dataKas_HR.TIME)<time_break1)[:,0]\n",
    "#indices2 = np.argwhere((np.array(dataKas_HR.TIME)>time_break1) & (np.array(dataKas_HR.TIME)<time_break2))[:,0]\n",
    "#indices3 = np.argwhere(np.array(dataKas_HR.TIME)>time_break2)[:,0]\n",
    "indices1 = np.argwhere(np.array(dataKas_noXT.TIME)<time_break1)[:,0]\n",
    "indices2 = np.argwhere((np.array(dataKas_noXT.TIME)>time_break1) & (np.array(dataKas_noXT.TIME)<time_break2))[:,0]\n",
    "indices3 = np.argwhere(np.array(dataKas_noXT.TIME)>time_break2)[:,0]\n",
    "\n",
    "dataKas_HR_jitter_bsln_drift = np.zeros(len(dataKas_HR_jitter_bsln))\n",
    "n1 = len(indices1)\n",
    "n2 = len(indices2)\n",
    "n3 = len(indices3)\n",
    "\n",
    "#idxsort = np.argsort(timeKas_HR)\n",
    "#ax0.scatter(np.arange(len(idxsort)), dataKas_HR.SIGNAL[idxsort], marker=\".\", s=5)\n",
    "#ax1.scatter(dataKas_HR.TIME, dataKas_HR.SIGNAL,marker=\".\", s=5, color='black')\n",
    "ax1.scatter(dataKas_noXT.TIME, dataKas_noXT.SIGNAL,marker=\".\", s=5, color='black')\n",
    "ax1.set_xlabel(\"UTime\")\n",
    "ax1.set_ylabel(\"PH of events (a.u.)\")\n",
    "ax1.set_title(\"Raw PH\")\n",
    "ax2.scatter(dataKas_noXT.TIME, dataKas_HR_jitter_bsln,marker=\".\", s=5, color='tab:green')\n",
    "ax2.set_xlabel(\"UTime\")\n",
    "ax2.set_ylabel(\"PH of events (a.u.)\")\n",
    "ax2.set_title(\"Jitter+BSLN corrected PH\")\n",
    "\n",
    "\n",
    "#dataKas_HR_jitter_bsln_drift[0:n1] = applyCorr(ydata=dataKas_HR_jitter_bsln[indices1], deg=1, xdata=dataKas_HR.TIME[indices1],\n",
    "#                                          ax0=ax3, ax1=ax4, alpha=1)\n",
    "#dataKas_HR_jitter_bsln_drift[0:n1] = applyCorr2(ydata=dataKas_HR_jitter_bsln[dataKas_noXT.TIME<time_break1], deg=1, \n",
    "#                                               xdata=dataKas_noXT[dataKas_noXT.TIME<time_break1].TIME,\n",
    "#                                               ax0=ax3, ax1=ax4, alpha=1)\n",
    "timeCorr1 = applyCorr(ydata=dataKas_HR_jitter_bsln[dataKas_noXT.TIME<time_break1], deg=1, \n",
    "                      xdata=dataKas_noXT[dataKas_noXT.TIME<time_break1].TIME, verbose=0)\n",
    "dataKas_HR_jitter_bsln_drift[0:n1] = timeCorr1.ydata_corr\n",
    "timeCorr1.plotDataFit(ax0=ax3, alpha=0.5, size=1)\n",
    "timeCorr1.plotDataCorrFit(ax0=ax4, alpha=0.5, size=1)\n",
    "ax3.set_xlabel(\"UTime (time1)\")\n",
    "ax3.set_ylabel(\"PH of events (a.u.)\")\n",
    "ax3.set_title(\"J+B corr PH - time1\")\n",
    "ax4.set_xlabel(\"UTime (time1)\")\n",
    "ax4.set_ylabel(\"PH of events (a.u.)\")\n",
    "ax4.set_title(\"J+B+Drift Corr PH - time1\")\n",
    "\n",
    "\n",
    "#dataKas_HR_jitter_bsln_drift[n1:(n1+n2)] = applyCorr(ydata=dataKas_HR_jitter_bsln[indices2],deg=1, xdata=dataKas_HR.TIME[indices2],\n",
    "#                                          ax0=ax5, ax1=ax6, alpha=1)\n",
    "#dataKas_HR_jitter_bsln_drift[n1:(n1+n2)] = applyCorr2(ydata=dataKas_HR_jitter_bsln[(dataKas_noXT.TIME>time_break1) & (dataKas_noXT.TIME<time_break2)], \n",
    "#                                                     xdata=dataKas_noXT[(dataKas_noXT.TIME>time_break1) & (dataKas_noXT.TIME<time_break2)].TIME,\n",
    "#                                                     deg=1, ax0=ax5, ax1=ax6, alpha=1)\n",
    "timeCorr2 = applyCorr(ydata=dataKas_HR_jitter_bsln[(dataKas_noXT.TIME>time_break1) & (dataKas_noXT.TIME<time_break2)],\n",
    "                      xdata=dataKas_noXT[(dataKas_noXT.TIME>time_break1) & (dataKas_noXT.TIME<time_break2)].TIME,\n",
    "                      deg=1, verbose=0)\n",
    "dataKas_HR_jitter_bsln_drift[n1:(n1+n2)] = timeCorr2.ydata_corr\n",
    "timeCorr2.plotDataFit(ax0=ax5, alpha=0.5, size=1)\n",
    "timeCorr2.plotDataCorrFit(ax0=ax6, alpha=0.5, size=1) \n",
    "\n",
    "ax5.set_xlabel(\"UTime (time2)\")\n",
    "ax5.set_ylabel(\"PH of events (a.u.)\")\n",
    "ax5.set_title(\"J+B corr PH - time2\")\n",
    "ax6.set_xlabel(\"UTime (time2)\")\n",
    "ax6.set_ylabel(\"Corrected PH of events (a.u.)\")\n",
    "ax6.set_title(\"J+B+Drift Corr PH - time2\")\n",
    "\n",
    "#dataKas_HR_jitter_bsln_drift[(n1+n2):(n1+n2+n3)] = applyCorr(ydata=dataKas_HR_jitter_bsln[indices3],deg=1, xdata=dataKas_HR.TIME[indices3],\n",
    "#                                          ax0=ax7, ax1=ax8, alpha=1)\n",
    "#dataKas_HR_jitter_bsln_drift[(n1+n2):(n1+n2+n3)] = applyCorr2(ydata=dataKas_HR_jitter_bsln[dataKas_noXT.TIME>time_break2], \n",
    "#                                                             xdata=dataKas_noXT.TIME[dataKas_noXT.TIME>time_break2],\n",
    "#                                                             deg=1,ax0=ax7, ax1=ax8, alpha=1)    \n",
    "timeCorr3 = applyCorr(ydata=dataKas_HR_jitter_bsln[dataKas_noXT.TIME>time_break2],\n",
    "                      xdata=dataKas_noXT.TIME[dataKas_noXT.TIME>time_break2],\n",
    "                      deg=1,verbose=0)\n",
    "dataKas_HR_jitter_bsln_drift[(n1+n2):(n1+n2+n3)] = timeCorr3.ydata_corr\n",
    "timeCorr3.plotDataFit(ax0=ax7, alpha=0.5, size=1)\n",
    "timeCorr3.plotDataCorrFit(ax0=ax8, alpha=0.5, size=1) \n",
    "\n",
    "ax7.set_xlabel(\"UTime (time3)\")\n",
    "ax7.set_ylabel(\"PH of events (a.u.)\")\n",
    "ax7.set_title(\"J+B corr PH - time3\")\n",
    "ax8.set_xlabel(\"UTime (time3)\")\n",
    "ax8.set_ylabel(\"Corrected PH of events (a.u.)\")\n",
    "ax8.set_title(\"J+B+Drift Corr PH - time3\")\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "#print(type(dataKas_HR_jitter))\n",
    "#print(type(dataKas_HR_jitter_bsln))\n",
    "#print(type(dataKas_HR_jitter_bsln_drift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare NICO & MAITE corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = resDir + \"/dataKas_cross.csv\"\n",
    "df = pandas.read_csv(csvFile, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myphase = dataKas_noXT.PHI- 1.*np.trunc(dataKas_noXT.PHI/0.5)\n",
    "fig = plt.figure(figsize=(8, 12))\n",
    "ax1 = fig.add_subplot(3,2,1)\n",
    "ax1.scatter(myphase,dataKas_HR_jitter_bsln_drift, s=1, alpha=0.5, label=\"Maite\")\n",
    "ax1.set_xlabel(\"PHASE\")\n",
    "ax1.legend()\n",
    "ax1.grid()\n",
    "ax2 = fig.add_subplot(3,2,2)\n",
    "ax2.scatter(df.PHI,df.SIGNALcorr_phi, s=1, alpha=0.5,label=\"Nico\")\n",
    "ax2.set_xlabel(\"PHASE\")\n",
    "ax2.legend()\n",
    "ax2.grid()\n",
    "\n",
    "ax3 = fig.add_subplot(3,2,3)\n",
    "ax3.scatter(dataKas_noXT.TIME,dataKas_HR_jitter_bsln_drift, s=1, alpha=0.5, label=\"Maite\")\n",
    "ax3.set_xlabel(\"TIME\")\n",
    "ax3.grid()\n",
    "ax4 = fig.add_subplot(3,2,4)\n",
    "ax4.scatter(df.TIME,df.SIGNALcorr_time, s=1, alpha=0.5,label=\"Nico\")\n",
    "ax4.set_xlabel(\"TIME\")\n",
    "ax4.grid()\n",
    "\n",
    "ax5 = fig.add_subplot(3,2,5)\n",
    "ax5.scatter(dataKas_noXT.TIME,dataKas_HR_jitter_bsln_drift-df.SIGNALcorr_phi, s=1, alpha=0.5)\n",
    "ax5.grid()\n",
    "\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## SELECT THE LEVEL OF CORRECTION (MAITE'S) ###################################\n",
    "#dataKas_HR_corrected = np.copy(dataKas_HR_jitter_bsln)  # Kas no drift corrected   \n",
    "dataKb_HR_corrected = np.copy(dataKb_HR_jitter_bsln)  # Kbeta no drift corrected\n",
    "dataKas_HR_corrected = np.copy(dataKas_HR_jitter_bsln_drift)  \n",
    "print(len(dataKas_HR_corrected))\n",
    "print(dataKas_HR_corrected[0:10])\n",
    "\n",
    "############## SELECT THE LEVEL OF CORRECTION (NICO'S) ###################################\n",
    "#dataKas_HR_corrected = np.copy(df.SIGNALcorr_time)  \n",
    "#print(len(dataKas_HR_corrected))\n",
    "#print(dataKas_HR_corrected[0:10])\n",
    "\n",
    "corrected =\"jitter_bsln_drift\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit gaussians, create Gain scale and calibrate energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-calibration histogram\n",
    "plt.close()\n",
    "nbinsKas = 60\n",
    "nbinsKb = 50\n",
    "if plen == 8000:\n",
    "    centresA=[5889,5898] # for pL8000\n",
    "    centresB=6368\n",
    "elif plen == 4096:\n",
    "    centresA=[7855,7865] # for pL4096\n",
    "    centresB=8345\n",
    "(mean1bsln, mean2bsln, mean3bsln) = fit3gauss2hist(data1=1e3*dataKas_HR_corrected, data2=1e3*dataKb_HR_corrected,\n",
    "                                        a1=0.06, a2=0.12, a3=0.1, sig1=5, sig2=5, sig3=5, \n",
    "                                        mean1=centresA[0], mean2=centresA[1], mean3=centresB,\n",
    "                                        nbins1=nbinsKas, nbins2=nbinsKb, \n",
    "                                        xlab=\"reconstructed PH (a.u.)\", plot=True, xsize=12,ysize=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gain scale Ka2, Ka1, Kb\n",
    "#plt.close()\n",
    "calib_lines = tuple([float(x) for x in (lines)])\n",
    "recon_lines = (mean1bsln,mean2bsln, mean3bsln)\n",
    "\n",
    "#calib_lines = tuple([float(x) for x in (lines[0:2])])\n",
    "#print(calib_lines)\n",
    "#recon_lines = (mean1bsln,mean2bsln)\n",
    "\n",
    "coefs = gainScalePolyFit(xData=recon_lines, yData=calib_lines, deg=1, ylab=\"MnK Lines energies (eV)\", xsize=10, ysize=4)\n",
    "print(\"gain scale coefs=\", coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minEeV_Ka=5860\n",
    "maxEeV_Ka=5920\n",
    "#minEeV_Ka=5880\n",
    "#maxEeV_Ka=5905\n",
    "\n",
    "minEeV_Kb=6450\n",
    "maxEeV_Kb=6505\n",
    "# recalibrate energies\n",
    "enerKas_HR_corrected = np.zeros(len(dataKas_HR_corrected))\n",
    "enerKb_HR_corrected = np.zeros(len(dataKb_HR_corrected))\n",
    "\n",
    "for i in range(len(coefs)):\n",
    "    enerKas_HR_corrected += coefs[i] * (1e3*dataKas_HR_corrected)**(i)\n",
    "enerKas_HR_corrected = enerKas_HR_corrected[(enerKas_HR_corrected > minEeV_Ka) & (enerKas_HR_corrected < maxEeV_Ka)]\n",
    "\n",
    "for i in range(len(coefs)):\n",
    "    enerKb_HR_corrected += coefs[i] * (1e3*dataKb_HR_corrected)**(i)\n",
    "enerKb_HR_corrected = enerKb_HR_corrected[(enerKb_HR_corrected>minEeV_Kb) & (enerKb_HR_corrected<maxEeV_Kb)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Fit histogram of corrected+gainscale_calib0 energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Test different number of bins and see how the residuals respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Plot residuals curve to select best number of bins for Kas and Kb\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "fitVoigt2hist(data=enerKas_HR_corrected, lines=MnKas, nbins=np.arange(20,200,20), ax0=ax1)\n",
    "ax1.set_title(\"MnKas\")\n",
    "\n",
    "fitVoigt2hist(data=enerKb_HR_corrected, lines=MnKb, nbins=np.arange(40,150,10), ax0=ax2)\n",
    "ax2.set_title(\"MnKb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Use the range of number of bins where residuals are quite estable and use them to get different FWHM; then take median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "# Calculate mean 'fit' for range of acceptable number of bins in Kas range\n",
    "#                                                               ===========\n",
    "(ibmin, ibmax) = (100, 300)\n",
    "fwhm_G = list()\n",
    "err_fwhm_G = list()\n",
    "nbins = list()\n",
    "for nbinsKas in np.arange(ibmin, ibmax, 10):\n",
    "    fw, efw, vv_fit = fitVoigt2hist(data=enerKas_HR_corrected, lines=MnKas, nbins=int(nbinsKas), ax0=ax1)    \n",
    "    plt.clf()\n",
    "    if fw < 0 or efw == 0:\n",
    "        continue\n",
    "    fwhm_G.append(fw)\n",
    "    err_fwhm_G.append(efw)\n",
    "    nbins.append(nbinsKas)\n",
    "print(\"FWHM_Gs=\", np.array2string(np.asarray(fwhm_G), formatter={'float_kind':lambda x: \"%.3f\" % x}))\n",
    "median_fwhm_G = np.median(fwhm_G)\n",
    "median_err_fwhm_G = np.sum(abs(np.asarray(fwhm_G)-median_fwhm_G))/len(fwhm_G)\n",
    "median_index = min(range(len(fwhm_G)), key=lambda i: abs(fwhm_G[i]-median_fwhm_G))\n",
    "nbinsKas = nbins[median_index]\n",
    "print(\"median_index=\", median_index)\n",
    "print(\"FWHM_G[median_index]=\",fwhm_G[median_index])\n",
    "print(\"ERR_FWHM_G[median_index]=\",err_fwhm_G[median_index])\n",
    "print(\"nbinsKas[median_index]=\", nbins[median_index])\n",
    "\n",
    "print(\"Using \", len(fwhm_G), \"different number of bins\")\n",
    "txt_Kas = '{:0.2f}'.format(median_fwhm_G) + \"+/-\" + '{:0.2f}'.format(max(median_err_fwhm_G, err_fwhm_G[median_index])) + \"eV\"\n",
    "print(\"Median FWHM_G(Kas)=\", txt_Kas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "# Calculate mean 'fit' for range of acceptable number of bins in Kb range\n",
    "#                                                               ===========\n",
    "(ibmin, ibmax) = (50, 100)\n",
    "fwhm_G = list()\n",
    "err_fwhm_G = list()\n",
    "nbins = list()\n",
    "for nbinsKb in np.arange(ibmin, ibmax, 10):\n",
    "    fw, efw, vv_fit = fitVoigt2hist(data=enerKb_HR_corrected, lines=MnKb, nbins=int(nbinsKb), ax0=ax2)    \n",
    "    plt.clf()\n",
    "    if efw == 0 or fw < 0:\n",
    "        continue\n",
    "    fwhm_G.append(fw)\n",
    "    err_fwhm_G.append(efw)\n",
    "    nbins.append(nbinsKb)\n",
    "print(\"FWHM_Gs=\", np.array2string(np.asarray(fwhm_G), formatter={'float_kind':lambda x: \"%.3f\" % x}))\n",
    "median_fwhm_G = np.median(fwhm_G)\n",
    "median_err_fwhm_G = np.sum(abs(np.asarray(fwhm_G)-median_fwhm_G))/len(fwhm_G)\n",
    "median_index = min(range(len(fwhm_G)), key=lambda i: abs(fwhm_G[i]-median_fwhm_G))\n",
    "nbinsKb = nbins[median_index]\n",
    "print(\"median_index=\", median_index)\n",
    "print(\"FWHM_G[median_index]=\",fwhm_G[median_index])\n",
    "print(\"ERR_FWHM_G[median_index]=\",err_fwhm_G[median_index])\n",
    "print(\"nbinsKb[median_index]=\", nbins[median_index])\n",
    "\n",
    "txt_Kb = '{:0.2f}'.format(median_fwhm_G) + \"+/-\" + '{:0.2f}'.format(max(median_err_fwhm_G, err_fwhm_G[median_index])) + \"eV\"\n",
    "print(\"Median FWHM_G(Kb)=\", txt_Kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "#plt.close()\n",
    "# Plot representative (median) fitting \n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.suptitle(\"Voigt fit to calib0 energies\")\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "\n",
    "print(\"Using nbinsKas=\", nbinsKas, \"from median estimation\")\n",
    "print(\"Using nbinsKb=\", nbinsKb, \"from median estimation\")\n",
    "\n",
    "nlines_Kas = MnKas.getNumber() \n",
    "nlines_Kb = MnKb.getNumber()\n",
    "nlines = nlines_Kas + nlines_Kb \n",
    "lines_centres_vv = np.zeros(nlines)\n",
    "\n",
    "fwhm_G, err_fwhm_G, vvmod = fitVoigt2hist(data=enerKas_HR_corrected, lines=MnKas, nbins=int(nbinsKas), ax0=ax1)\n",
    "print(fwhm_G, err_fwhm_G)\n",
    "for i in range(nlines_Kas):\n",
    "     lines_centres_vv[i] = vvmod.param_sets[i*4][0]\n",
    "info = \"FWHM=\" + txt_Kas + \"\\n Total counts=\" + str(len(enerKas_HR_corrected))\n",
    "ax1.text(0.30, 0.10, info,verticalalignment='bottom', horizontalalignment='right',transform=ax1.transAxes, fontsize=8)\n",
    "\n",
    "fwhm_G, err_fwhm_G, vvmod = fitVoigt2hist(data=enerKb_HR_corrected, lines=MnKb, nbins=int(nbinsKb), ax0=ax2)\n",
    "print(fwhm_G, err_fwhm_G)\n",
    "for i in range(nlines_Kb):\n",
    "    j = i + nlines_Kas\n",
    "    lines_centres_vv[j] = vvmod.param_sets[i*4][0]\n",
    "info = \"FWHM=\" + txt_Kb + \"\\n Total counts=\" + str(len(enerKb_HR_corrected))\n",
    "ax2.text(0.30, 0.10, info,verticalalignment='bottom', horizontalalignment='right',transform=ax2.transAxes, fontsize=8)\n",
    "\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recalibrate energies:\n",
    "      - get new gain scale with fitted line centres\n",
    "      - recalibrate energies\n",
    "      - fit again to get FWHM more precisely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse au to energy transformation of lines centres using gain scale\n",
    "#lines_centres_Kas \n",
    "# Ecal = coefs[0] + coefs[1] * PHau + coefs[2] * PHau^2 + ....\n",
    "# to get roots:    0 = coefs[0]-Ecal + coefs[1] * PHau + coefs[2] * PHau^2 + ....\n",
    "PHau = np.zeros(nlines)\n",
    "newcoefs = np.zeros(len(coefs))\n",
    "np.copyto(newcoefs, coefs)\n",
    "#print(coefs)\n",
    "for i in range(nlines):  \n",
    "    line = lines_centres_vv[i]\n",
    "    #print(\"line=\", line)\n",
    "    coef0 = coefs[0] - line\n",
    "    newcoefs[0] = coef0\n",
    "    calpoly = P(newcoefs)\n",
    "    roots = calpoly.roots()\n",
    "    #print(\"Roots=\", roots)\n",
    "    PHau[i] = roots[np.abs(line-roots).argmin()]\n",
    "    #PHau[i] = max(calpoly.roots())\n",
    "    #if abs(line - PHau[i]) > 1000:\n",
    "    #    PHau[i] = min(calpoly.roots())\n",
    "    #if abs(line - PHau[i]) > 5000:\n",
    "    #    raise RuntimeError(\"PH root in a.u. is too different from line Energy (eV)\")\n",
    "    \n",
    "    #print(calpoly.roots())\n",
    "    print(\"PH for \", line, \"=\", PHau[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NEW gain scale Ka2, Ka1, Kb\n",
    "#plt.close()\n",
    "ph_lines = np.sort(PHau)\n",
    "print(\"Creating new gain scale using lines with Fitted Energies:\\n\", ph_lines)\n",
    "true_lines = np.sort(np.concatenate((MnKas.energies_eV, MnKb.energies_eV)))\n",
    "print(\"True energies of lines are:\\n\",true_lines)\n",
    "coefs_final = gainScalePolyFit(xData=ph_lines, yData=true_lines, deg=4, ylab=\"MnK Lines energies (eV)\")\n",
    "print(\"gain scale coefs=\", coefs_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL recalibration of energies\n",
    "enerKas_final = np.zeros(len(dataKas_HR_jitter_bsln))\n",
    "enerKb_final = np.zeros(len(dataKb_HR_jitter_bsln))\n",
    "\n",
    "for i in range(len(coefs_final)):\n",
    "    enerKas_final += coefs_final[i] * (1e3*dataKas_HR_jitter_bsln)**(i)\n",
    "    #enerKas_final = inter + slope * 1e3*dataKas_HR_jitter_bsln # eV\n",
    "enerKas_final = enerKas_final[(enerKas_final > minEeV_Ka) & (enerKas_final < maxEeV_Ka)]\n",
    "\n",
    "for i in range(len(coefs_final)):\n",
    "    enerKb_final += coefs_final[i] * (1e3*dataKb_HR_jitter_bsln)**(i)\n",
    "    #enerKb_final = inter + slope * 1e3*dataKb_HR_jitter_bsln # eV\n",
    "enerKb_final = enerKb_final[(enerKb_final>minEeV_Kb) & (enerKb_final<maxEeV_Kb)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "# Calculate median 'fit' for range of acceptable number of bins in Kas range\n",
    "#                                                               ===========\n",
    "(ibmin, ibmax) = (100, 250)\n",
    "fwhm_G = list()\n",
    "err_fwhm_G = list()\n",
    "nbins = list()\n",
    "for nbinsKas in np.arange(ibmin, ibmax, 10):\n",
    "    fw, efw, vv_fit = fitVoigt2hist(data=enerKas_final, lines=MnKas, nbins=int(nbinsKas), ax0=ax1)    \n",
    "    plt.clf()\n",
    "    if fw < 0 or efw == 0:\n",
    "        continue\n",
    "    fwhm_G.append(fw)\n",
    "    err_fwhm_G.append(efw)\n",
    "    nbins.append(nbinsKas)\n",
    "print(\"FWHM_Gs=\", np.array2string(np.asarray(fwhm_G), formatter={'float_kind':lambda x: \"%.3f\" % x}))\n",
    "median_fwhm_G = np.median(fwhm_G)\n",
    "median_err_fwhm_G = np.sum(abs(np.asarray(fwhm_G)-median_fwhm_G))/len(fwhm_G)\n",
    "median_index = min(range(len(fwhm_G)), key=lambda i: abs(fwhm_G[i]-median_fwhm_G))\n",
    "nbinsKas = nbins[median_index]\n",
    "print(\"median_index=\", median_index)\n",
    "print(\"FWHM_G[median_index]=\",fwhm_G[median_index])\n",
    "print(\"ERR_FWHM_G[median_index]=\",err_fwhm_G[median_index])\n",
    "print(\"nbinsKas[median_index]=\", nbins[median_index])\n",
    "\n",
    "print(\"Using \", len(fwhm_G), \"different number of bins\")\n",
    "txt_Kas = '{:0.2f}'.format(median_fwhm_G) + \"+/-\" + '{:0.2f}'.format(max(median_err_fwhm_G, err_fwhm_G[median_index])) + \"eV\"\n",
    "print(\"Median FWHM_G(Kas)=\", txt_Kas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "plt.close()\n",
    "# Plot representative (median) fitting \n",
    "#                    =====================\n",
    "fig = plt.figure(figsize=(14, 6.5))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "\n",
    "fwhm_G, err_fwhm_G, vvmod = fitVoigt2hist(data=enerKas_final, lines=MnKas, nbins=int(nbinsKas), ax0=ax1)\n",
    "#print(fwhm_G, err_fwhm_G)\n",
    "info = \"FWHM=\" + txt_Kas + \"\\n Total counts=\" + str(len(enerKas_final))\n",
    "ax1.text(0.30, 0.10, info,verticalalignment='bottom', horizontalalignment='right',transform=ax1.transAxes, fontsize=8)\n",
    "ax1.axvline(MnKas.energies_eV[0], ls=\"--\", color=\"gray\")\n",
    "ax1.set_title(\"Representative 'median' fitting\")\n",
    "\n",
    "\n",
    "outfig=resDir + \"/fit_\" + \"pL\" + str(plen) + \"_\" + method + str(oflen) + pBstr + \"_final.png\"\n",
    "fig.tight_layout()\n",
    "fig.savefig(outfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353.333px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
